<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Transformer Library: include/optimizer.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Transformer Library
   </div>
   <div id="projectbrief">A minimal C++ tensor library with automatic differentiation</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function() { init_codefold(0); });
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('optimizer_8hpp_source.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">optimizer.hpp</div></div>
</div><!--header-->
<div class="contents">
<a href="optimizer_8hpp.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno">    1</span> </div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span><span class="preprocessor">#pragma once</span></div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno">   10</span> </div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span><span class="preprocessor">#include &lt;algorithm&gt;</span></div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span><span class="preprocessor">#include &lt;cmath&gt;</span></div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno">   13</span><span class="preprocessor">#include &lt;cstddef&gt;</span></div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno">   14</span><span class="preprocessor">#include &lt;memory&gt;</span></div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span><span class="preprocessor">#include &lt;utility&gt;</span></div>
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno">   16</span><span class="preprocessor">#include &lt;vector&gt;</span></div>
<div class="line"><a id="l00017" name="l00017"></a><span class="lineno">   17</span> </div>
<div class="line"><a id="l00018" name="l00018"></a><span class="lineno">   18</span><span class="preprocessor">#include &quot;<a class="code" href="tensor_8hpp.html">tensor.hpp</a>&quot;</span></div>
<div class="line"><a id="l00019" name="l00019"></a><span class="lineno">   19</span><span class="preprocessor">#include &quot;<a class="code" href="utils_8hpp.html">utils.hpp</a>&quot;</span></div>
<div class="line"><a id="l00020" name="l00020"></a><span class="lineno">   20</span> </div>
<div class="foldopen" id="foldopen00021" data-start="{" data-end="}">
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno"><a class="line" href="namespaceoptim.html">   21</a></span><span class="keyword">namespace </span><a class="code hl_namespace" href="namespaceoptim.html">optim</a> {</div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno">   22</span> </div>
<div class="foldopen" id="foldopen00030" data-start="{" data-end="};">
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno"><a class="line" href="classoptim_1_1Optimizer.html">   30</a></span><span class="keyword">class </span><a class="code hl_class" href="classoptim_1_1Optimizer.html">Optimizer</a> {</div>
<div class="line"><a id="l00031" name="l00031"></a><span class="lineno">   31</span> <span class="keyword">protected</span>:</div>
<div class="line"><a id="l00032" name="l00032"></a><span class="lineno"><a class="line" href="classoptim_1_1Optimizer.html#aad43a44085c393e55f9f21012ad78e11">   32</a></span>  std::vector&lt;Tensor&gt; <a class="code hl_variable" href="classoptim_1_1Optimizer.html#aad43a44085c393e55f9f21012ad78e11">params_</a>;  </div>
<div class="line"><a id="l00033" name="l00033"></a><span class="lineno"><a class="line" href="classoptim_1_1Optimizer.html#a76053e62b3ab69ec9fecf22d3909972e">   33</a></span>  <span class="keywordtype">size_t</span> <a class="code hl_variable" href="classoptim_1_1Optimizer.html#a76053e62b3ab69ec9fecf22d3909972e">step_count_</a>;           </div>
<div class="line"><a id="l00034" name="l00034"></a><span class="lineno">   34</span> </div>
<div class="line"><a id="l00035" name="l00035"></a><span class="lineno">   35</span> <span class="keyword">public</span>:</div>
<div class="foldopen" id="foldopen00040" data-start="{" data-end="}">
<div class="line"><a id="l00040" name="l00040"></a><span class="lineno"><a class="line" href="classoptim_1_1Optimizer.html#a7dfe439ca1d1fd030c87b01566c33757">   40</a></span>  <span class="keyword">explicit</span> <a class="code hl_function" href="classoptim_1_1Optimizer.html#a7dfe439ca1d1fd030c87b01566c33757">Optimizer</a>(std::vector&lt;Tensor&gt; params)</div>
<div class="line"><a id="l00041" name="l00041"></a><span class="lineno">   41</span>      : <a class="code hl_variable" href="classoptim_1_1Optimizer.html#aad43a44085c393e55f9f21012ad78e11">params_</a>(std::move(params)), <a class="code hl_variable" href="classoptim_1_1Optimizer.html#a76053e62b3ab69ec9fecf22d3909972e">step_count_</a>(0) {}</div>
</div>
<div class="line"><a id="l00042" name="l00042"></a><span class="lineno"><a class="line" href="classoptim_1_1Optimizer.html#a8844cd33a9d0ac230ebc6f47b03efd27">   42</a></span>  <span class="keyword">virtual</span> <a class="code hl_function" href="classoptim_1_1Optimizer.html#a8844cd33a9d0ac230ebc6f47b03efd27">~Optimizer</a>() = <span class="keywordflow">default</span>;</div>
<div class="line"><a id="l00043" name="l00043"></a><span class="lineno">   43</span> </div>
<div class="foldopen" id="foldopen00047" data-start="{" data-end="}">
<div class="line"><a id="l00047" name="l00047"></a><span class="lineno"><a class="line" href="classoptim_1_1Optimizer.html#a37b4a35ba858e7f42b59b0fa70a161fe">   47</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="classoptim_1_1Optimizer.html#a37b4a35ba858e7f42b59b0fa70a161fe">zero_grad</a>() {</div>
<div class="line"><a id="l00048" name="l00048"></a><span class="lineno">   48</span>    <span class="keywordflow">for</span> (<span class="keyword">auto</span>&amp; param : <a class="code hl_variable" href="classoptim_1_1Optimizer.html#aad43a44085c393e55f9f21012ad78e11">params_</a>) {</div>
<div class="line"><a id="l00049" name="l00049"></a><span class="lineno">   49</span>      param.zero_grad();</div>
<div class="line"><a id="l00050" name="l00050"></a><span class="lineno">   50</span>    }</div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno">   51</span>  }</div>
</div>
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno">   52</span> </div>
<div class="line"><a id="l00056" name="l00056"></a><span class="lineno"><a class="line" href="classoptim_1_1Optimizer.html#ad9a5904b78707346eeab961629342af7">   56</a></span>  <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code hl_function" href="classoptim_1_1Optimizer.html#ad9a5904b78707346eeab961629342af7">step</a>() = 0;</div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno">   57</span> </div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno">   58</span> <span class="keyword">protected</span>:</div>
<div class="foldopen" id="foldopen00064" data-start="{" data-end="}">
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno"><a class="line" href="classoptim_1_1Optimizer.html#ae7308bc1b1f376b6a9cb7ae66c3af88e">   64</a></span>  <span class="keyword">static</span> <span class="keywordtype">void</span> <a class="code hl_function" href="classoptim_1_1Optimizer.html#ae7308bc1b1f376b6a9cb7ae66c3af88e">ensure_state_size</a>(std::vector&lt;float&gt;&amp; state, <span class="keywordtype">size_t</span> target) {</div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno">   65</span>    <span class="keywordflow">if</span> (state.size() != target) {</div>
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno">   66</span>      state.assign(target, 0.0f);</div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno">   67</span>    }</div>
<div class="line"><a id="l00068" name="l00068"></a><span class="lineno">   68</span>  }</div>
</div>
<div class="line"><a id="l00069" name="l00069"></a><span class="lineno">   69</span> </div>
<div class="foldopen" id="foldopen00075" data-start="{" data-end="}">
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno"><a class="line" href="classoptim_1_1Optimizer.html#ae49f7491e2f65b815afcfd94d5f1671b">   75</a></span>  <span class="keyword">static</span> <span class="keywordtype">bool</span> <a class="code hl_function" href="classoptim_1_1Optimizer.html#ae49f7491e2f65b815afcfd94d5f1671b">valid_param</a>(<span class="keyword">const</span> <a class="code hl_struct" href="structTensor.html">Tensor</a>&amp; t) {</div>
<div class="line"><a id="l00076" name="l00076"></a><span class="lineno">   76</span>    <span class="keywordflow">return</span> t.<a class="code hl_variable" href="structTensor.html#a10ca340abccb2fa3476d3ec64346c238">numel</a> &gt; 0 &amp;&amp; t.<a class="code hl_function" href="structTensor.html#a68b3bf158149399d366aee5cf21aa951">data</a>() != <span class="keyword">nullptr</span> &amp;&amp; t.<a class="code hl_function" href="structTensor.html#afaed2ad287228df5d00eb689ad8d3776">grad</a>() != <span class="keyword">nullptr</span>;</div>
<div class="line"><a id="l00077" name="l00077"></a><span class="lineno">   77</span>  }</div>
</div>
<div class="line"><a id="l00078" name="l00078"></a><span class="lineno">   78</span>};</div>
</div>
<div class="line"><a id="l00079" name="l00079"></a><span class="lineno">   79</span> </div>
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno">   85</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Scheduler&gt;</div>
<div class="foldopen" id="foldopen00086" data-start="{" data-end="};">
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno"><a class="line" href="classoptim_1_1OptimizerWithScheduler.html">   86</a></span><span class="keyword">class </span><a class="code hl_class" href="classoptim_1_1OptimizerWithScheduler.html">OptimizerWithScheduler</a> : <span class="keyword">public</span> <a class="code hl_class" href="classoptim_1_1Optimizer.html">Optimizer</a> {</div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span> <span class="keyword">protected</span>:</div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno"><a class="line" href="classoptim_1_1OptimizerWithScheduler.html#a6561fdfdb4ca2e0bcda311f6528bc33d">   88</a></span>  Scheduler* <a class="code hl_variable" href="classoptim_1_1OptimizerWithScheduler.html#a6561fdfdb4ca2e0bcda311f6528bc33d">scheduler_</a>;  </div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno">   89</span> </div>
<div class="line"><a id="l00090" name="l00090"></a><span class="lineno">   90</span> <span class="keyword">public</span>:</div>
<div class="foldopen" id="foldopen00096" data-start="{" data-end="}">
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno"><a class="line" href="classoptim_1_1OptimizerWithScheduler.html#afeb623ea67dc878f3cbaa6d622aa1b9b">   96</a></span>  <a class="code hl_function" href="classoptim_1_1OptimizerWithScheduler.html#afeb623ea67dc878f3cbaa6d622aa1b9b">OptimizerWithScheduler</a>(std::vector&lt;Tensor&gt; params, Scheduler&amp; scheduler)</div>
<div class="line"><a id="l00097" name="l00097"></a><span class="lineno">   97</span>      : <a class="code hl_class" href="classoptim_1_1Optimizer.html">Optimizer</a>(std::move(params)), <a class="code hl_variable" href="classoptim_1_1OptimizerWithScheduler.html#a6561fdfdb4ca2e0bcda311f6528bc33d">scheduler_</a>(&amp;scheduler) {}</div>
</div>
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno">   98</span>};</div>
</div>
<div class="line"><a id="l00099" name="l00099"></a><span class="lineno">   99</span> </div>
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno">  107</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Scheduler&gt;</div>
<div class="foldopen" id="foldopen00108" data-start="{" data-end="};">
<div class="line"><a id="l00108" name="l00108"></a><span class="lineno"><a class="line" href="classoptim_1_1SGD.html">  108</a></span><span class="keyword">class </span><a class="code hl_class" href="classoptim_1_1SGD.html">SGD</a> : <span class="keyword">public</span> <a class="code hl_class" href="classoptim_1_1OptimizerWithScheduler.html">OptimizerWithScheduler</a>&lt;Scheduler&gt; {</div>
<div class="line"><a id="l00109" name="l00109"></a><span class="lineno">  109</span> <span class="keyword">public</span>:</div>
<div class="foldopen" id="foldopen00116" data-start="{" data-end="}">
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno"><a class="line" href="classoptim_1_1SGD.html#a7a4eec9b6d27035ec02ffb51422e88ff">  116</a></span>  <a class="code hl_function" href="classoptim_1_1SGD.html#a7a4eec9b6d27035ec02ffb51422e88ff">SGD</a>(std::vector&lt;Tensor&gt; params, Scheduler&amp; scheduler,</div>
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno">  117</span>      <span class="keywordtype">float</span> momentum_beta = 0.0f)</div>
<div class="line"><a id="l00118" name="l00118"></a><span class="lineno">  118</span>      : <a class="code hl_class" href="classoptim_1_1OptimizerWithScheduler.html">OptimizerWithScheduler</a>&lt;Scheduler&gt;(std::move(params), scheduler),</div>
<div class="line"><a id="l00119" name="l00119"></a><span class="lineno">  119</span>        momentum_beta_(momentum_beta),</div>
<div class="line"><a id="l00120" name="l00120"></a><span class="lineno">  120</span>        momentum_(this-&gt;<a class="code hl_variable" href="classoptim_1_1Optimizer.html#aad43a44085c393e55f9f21012ad78e11">params_</a>.size()) {}</div>
</div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno">  121</span> </div>
<div class="foldopen" id="foldopen00125" data-start="{" data-end="}">
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno"><a class="line" href="classoptim_1_1SGD.html#af563ec82e2b7929afbd28dbf549b50af">  125</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="classoptim_1_1SGD.html#af563ec82e2b7929afbd28dbf549b50af">step</a>()<span class="keyword"> override </span>{</div>
<div class="line"><a id="l00126" name="l00126"></a><span class="lineno">  126</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> lr = this-&gt;<a class="code hl_variable" href="classoptim_1_1OptimizerWithScheduler.html#a6561fdfdb4ca2e0bcda311f6528bc33d">scheduler_</a>-&gt;get();</div>
<div class="line"><a id="l00127" name="l00127"></a><span class="lineno">  127</span>    ++this-&gt;<a class="code hl_variable" href="classoptim_1_1Optimizer.html#a76053e62b3ab69ec9fecf22d3909972e">step_count_</a>;</div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno">  128</span> </div>
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno">  129</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> idx = 0; idx &lt; this-&gt;<a class="code hl_variable" href="classoptim_1_1Optimizer.html#aad43a44085c393e55f9f21012ad78e11">params_</a>.size(); ++idx) {</div>
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno">  130</span>      <a class="code hl_struct" href="structTensor.html">Tensor</a>&amp; param = this-&gt;<a class="code hl_variable" href="classoptim_1_1Optimizer.html#aad43a44085c393e55f9f21012ad78e11">params_</a>[idx];</div>
<div class="line"><a id="l00131" name="l00131"></a><span class="lineno">  131</span>      <span class="keywordflow">if</span> (!<a class="code hl_function" href="classoptim_1_1Optimizer.html#ae49f7491e2f65b815afcfd94d5f1671b">Optimizer::valid_param</a>(param)) <span class="keywordflow">continue</span>;</div>
<div class="line"><a id="l00132" name="l00132"></a><span class="lineno">  132</span>      <span class="keywordtype">float</span>* data = param.<a class="code hl_function" href="structTensor.html#a68b3bf158149399d366aee5cf21aa951">data</a>();</div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno">  133</span>      <span class="keyword">const</span> <span class="keywordtype">float</span>* grad = param.<a class="code hl_function" href="structTensor.html#afaed2ad287228df5d00eb689ad8d3776">grad</a>();</div>
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno">  134</span>      <span class="keyword">const</span> <span class="keywordtype">size_t</span> n = param.<a class="code hl_variable" href="structTensor.html#a10ca340abccb2fa3476d3ec64346c238">numel</a>;</div>
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno">  135</span>      <span class="keywordflow">if</span> (momentum_beta_ != 0.0f) {</div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span>        <a class="code hl_function" href="classoptim_1_1Optimizer.html#ae7308bc1b1f376b6a9cb7ae66c3af88e">Optimizer::ensure_state_size</a>(momentum_[idx], n);</div>
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno">  137</span>        <span class="keyword">auto</span>&amp; momentum_vec = momentum_[idx];</div>
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno">  138</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; n; ++i) {</div>
<div class="line"><a id="l00139" name="l00139"></a><span class="lineno">  139</span>          momentum_vec[i] = momentum_beta_ * momentum_vec[i] + grad[i];</div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno">  140</span>          data[i] -= lr * momentum_vec[i];</div>
<div class="line"><a id="l00141" name="l00141"></a><span class="lineno">  141</span>        }</div>
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno">  142</span>      } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00143" name="l00143"></a><span class="lineno">  143</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; n; ++i) {</div>
<div class="line"><a id="l00144" name="l00144"></a><span class="lineno">  144</span>          data[i] -= lr * grad[i];</div>
<div class="line"><a id="l00145" name="l00145"></a><span class="lineno">  145</span>        }</div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno">  146</span>      }</div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno">  147</span>    }</div>
<div class="line"><a id="l00148" name="l00148"></a><span class="lineno">  148</span>  }</div>
</div>
<div class="line"><a id="l00149" name="l00149"></a><span class="lineno">  149</span> </div>
<div class="line"><a id="l00150" name="l00150"></a><span class="lineno">  150</span> <span class="keyword">private</span>:</div>
<div class="line"><a id="l00151" name="l00151"></a><span class="lineno">  151</span>  <span class="keywordtype">float</span> momentum_beta_;</div>
<div class="line"><a id="l00152" name="l00152"></a><span class="lineno">  152</span>  std::vector&lt;std::vector&lt;float&gt;&gt; momentum_;</div>
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno">  153</span>};</div>
</div>
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno">  154</span> </div>
<div class="line"><a id="l00163" name="l00163"></a><span class="lineno">  163</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Scheduler&gt;</div>
<div class="foldopen" id="foldopen00164" data-start="{" data-end="};">
<div class="line"><a id="l00164" name="l00164"></a><span class="lineno"><a class="line" href="classoptim_1_1Adam.html">  164</a></span><span class="keyword">class </span><a class="code hl_class" href="classoptim_1_1Adam.html">Adam</a> : <span class="keyword">public</span> <a class="code hl_class" href="classoptim_1_1OptimizerWithScheduler.html">OptimizerWithScheduler</a>&lt;Scheduler&gt; {</div>
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno">  165</span> <span class="keyword">public</span>:</div>
<div class="foldopen" id="foldopen00177" data-start="{" data-end="}">
<div class="line"><a id="l00177" name="l00177"></a><span class="lineno"><a class="line" href="classoptim_1_1Adam.html#ab9bc3c3903f4bc32af2e16d99b5ce566">  177</a></span>  <a class="code hl_function" href="classoptim_1_1Adam.html#ab9bc3c3903f4bc32af2e16d99b5ce566">Adam</a>(std::vector&lt;Tensor&gt; params, Scheduler&amp; scheduler, <span class="keywordtype">float</span> beta1 = 0.9f,</div>
<div class="line"><a id="l00178" name="l00178"></a><span class="lineno">  178</span>       <span class="keywordtype">float</span> beta2 = 0.999f, <span class="keywordtype">float</span> weight_decay = 0.0f,</div>
<div class="line"><a id="l00179" name="l00179"></a><span class="lineno">  179</span>       <span class="keywordtype">bool</span> use_weight_decay = <span class="keyword">false</span>, <span class="keywordtype">bool</span> amsgrad = <span class="keyword">false</span>,</div>
<div class="line"><a id="l00180" name="l00180"></a><span class="lineno">  180</span>       <span class="keywordtype">float</span> epsilon = 1e-8f)</div>
<div class="line"><a id="l00181" name="l00181"></a><span class="lineno">  181</span>      : <a class="code hl_class" href="classoptim_1_1OptimizerWithScheduler.html">OptimizerWithScheduler</a>&lt;Scheduler&gt;(std::move(params), scheduler),</div>
<div class="line"><a id="l00182" name="l00182"></a><span class="lineno">  182</span>        beta1_(beta1),</div>
<div class="line"><a id="l00183" name="l00183"></a><span class="lineno">  183</span>        beta2_(beta2),</div>
<div class="line"><a id="l00184" name="l00184"></a><span class="lineno">  184</span>        weight_decay_(weight_decay),</div>
<div class="line"><a id="l00185" name="l00185"></a><span class="lineno">  185</span>        use_weight_decay_(use_weight_decay),</div>
<div class="line"><a id="l00186" name="l00186"></a><span class="lineno">  186</span>        amsgrad_(amsgrad),</div>
<div class="line"><a id="l00187" name="l00187"></a><span class="lineno">  187</span>        epsilon_(epsilon),</div>
<div class="line"><a id="l00188" name="l00188"></a><span class="lineno">  188</span>        m1_(this-&gt;<a class="code hl_variable" href="classoptim_1_1Optimizer.html#aad43a44085c393e55f9f21012ad78e11">params_</a>.size()),</div>
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno">  189</span>        m2_(this-&gt;<a class="code hl_variable" href="classoptim_1_1Optimizer.html#aad43a44085c393e55f9f21012ad78e11">params_</a>.size()),</div>
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno">  190</span>        vhat_(amsgrad ? this-&gt;<a class="code hl_variable" href="classoptim_1_1Optimizer.html#aad43a44085c393e55f9f21012ad78e11">params_</a>.size() : 0) {}</div>
</div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span> </div>
<div class="foldopen" id="foldopen00195" data-start="{" data-end="}">
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno"><a class="line" href="classoptim_1_1Adam.html#ac94daadd6de7e3c908824638aa72736a">  195</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="classoptim_1_1Adam.html#ac94daadd6de7e3c908824638aa72736a">step</a>()<span class="keyword"> override </span>{</div>
<div class="line"><a id="l00196" name="l00196"></a><span class="lineno">  196</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> lr = this-&gt;<a class="code hl_variable" href="classoptim_1_1OptimizerWithScheduler.html#a6561fdfdb4ca2e0bcda311f6528bc33d">scheduler_</a>-&gt;get();</div>
<div class="line"><a id="l00197" name="l00197"></a><span class="lineno">  197</span>    ++this-&gt;<a class="code hl_variable" href="classoptim_1_1Optimizer.html#a76053e62b3ab69ec9fecf22d3909972e">step_count_</a>;</div>
<div class="line"><a id="l00198" name="l00198"></a><span class="lineno">  198</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> bc1 =</div>
<div class="line"><a id="l00199" name="l00199"></a><span class="lineno">  199</span>        1.0f - std::pow(beta1_, <span class="keyword">static_cast&lt;</span><span class="keywordtype">float</span><span class="keyword">&gt;</span>(this-&gt;<a class="code hl_variable" href="classoptim_1_1Optimizer.html#a76053e62b3ab69ec9fecf22d3909972e">step_count_</a>));</div>
<div class="line"><a id="l00200" name="l00200"></a><span class="lineno">  200</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> bc2 =</div>
<div class="line"><a id="l00201" name="l00201"></a><span class="lineno">  201</span>        1.0f - std::pow(beta2_, <span class="keyword">static_cast&lt;</span><span class="keywordtype">float</span><span class="keyword">&gt;</span>(this-&gt;<a class="code hl_variable" href="classoptim_1_1Optimizer.html#a76053e62b3ab69ec9fecf22d3909972e">step_count_</a>));</div>
<div class="line"><a id="l00202" name="l00202"></a><span class="lineno">  202</span> </div>
<div class="line"><a id="l00203" name="l00203"></a><span class="lineno">  203</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> idx = 0; idx &lt; this-&gt;<a class="code hl_variable" href="classoptim_1_1Optimizer.html#aad43a44085c393e55f9f21012ad78e11">params_</a>.size(); ++idx) {</div>
<div class="line"><a id="l00204" name="l00204"></a><span class="lineno">  204</span>      <a class="code hl_struct" href="structTensor.html">Tensor</a>&amp; param = this-&gt;<a class="code hl_variable" href="classoptim_1_1Optimizer.html#aad43a44085c393e55f9f21012ad78e11">params_</a>[idx];</div>
<div class="line"><a id="l00205" name="l00205"></a><span class="lineno">  205</span>      <span class="keywordflow">if</span> (!<a class="code hl_function" href="classoptim_1_1Optimizer.html#ae49f7491e2f65b815afcfd94d5f1671b">Optimizer::valid_param</a>(param)) <span class="keywordflow">continue</span>;</div>
<div class="line"><a id="l00206" name="l00206"></a><span class="lineno">  206</span>      <span class="keywordtype">float</span>* data = param.<a class="code hl_function" href="structTensor.html#a68b3bf158149399d366aee5cf21aa951">data</a>();</div>
<div class="line"><a id="l00207" name="l00207"></a><span class="lineno">  207</span>      <span class="keyword">const</span> <span class="keywordtype">float</span>* grad_ptr = param.<a class="code hl_function" href="structTensor.html#afaed2ad287228df5d00eb689ad8d3776">grad</a>();</div>
<div class="line"><a id="l00208" name="l00208"></a><span class="lineno">  208</span>      <span class="keyword">const</span> <span class="keywordtype">size_t</span> n = param.<a class="code hl_variable" href="structTensor.html#a10ca340abccb2fa3476d3ec64346c238">numel</a>;</div>
<div class="line"><a id="l00209" name="l00209"></a><span class="lineno">  209</span>      <a class="code hl_function" href="classoptim_1_1Optimizer.html#ae7308bc1b1f376b6a9cb7ae66c3af88e">Optimizer::ensure_state_size</a>(m1_[idx], n);</div>
<div class="line"><a id="l00210" name="l00210"></a><span class="lineno">  210</span>      <a class="code hl_function" href="classoptim_1_1Optimizer.html#ae7308bc1b1f376b6a9cb7ae66c3af88e">Optimizer::ensure_state_size</a>(m2_[idx], n);</div>
<div class="line"><a id="l00211" name="l00211"></a><span class="lineno">  211</span>      <span class="keywordflow">if</span> (amsgrad_) {</div>
<div class="line"><a id="l00212" name="l00212"></a><span class="lineno">  212</span>        <a class="code hl_function" href="classoptim_1_1Optimizer.html#ae7308bc1b1f376b6a9cb7ae66c3af88e">Optimizer::ensure_state_size</a>(vhat_[idx], n);</div>
<div class="line"><a id="l00213" name="l00213"></a><span class="lineno">  213</span>      }</div>
<div class="line"><a id="l00214" name="l00214"></a><span class="lineno">  214</span>      <span class="keyword">auto</span>&amp; m1_vec = m1_[idx];</div>
<div class="line"><a id="l00215" name="l00215"></a><span class="lineno">  215</span>      <span class="keyword">auto</span>&amp; m2_vec = m2_[idx];</div>
<div class="line"><a id="l00216" name="l00216"></a><span class="lineno">  216</span>      std::vector&lt;float&gt;* vhat_vec = amsgrad_ ? &amp;vhat_[idx] : <span class="keyword">nullptr</span>;</div>
<div class="line"><a id="l00217" name="l00217"></a><span class="lineno">  217</span> </div>
<div class="line"><a id="l00218" name="l00218"></a><span class="lineno">  218</span>      <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; n; ++i) {</div>
<div class="line"><a id="l00219" name="l00219"></a><span class="lineno">  219</span>        <span class="keywordtype">float</span> grad = grad_ptr[i];</div>
<div class="line"><a id="l00220" name="l00220"></a><span class="lineno">  220</span>        <span class="keywordflow">if</span> (weight_decay_ != 0.0f) {</div>
<div class="line"><a id="l00221" name="l00221"></a><span class="lineno">  221</span>          grad += weight_decay_ * data[i];</div>
<div class="line"><a id="l00222" name="l00222"></a><span class="lineno">  222</span>        }</div>
<div class="line"><a id="l00223" name="l00223"></a><span class="lineno">  223</span> </div>
<div class="line"><a id="l00224" name="l00224"></a><span class="lineno">  224</span>        m1_vec[i] = beta1_ * m1_vec[i] + (1.0f - beta1_) * grad;</div>
<div class="line"><a id="l00225" name="l00225"></a><span class="lineno">  225</span>        m2_vec[i] = beta2_ * m2_vec[i] + (1.0f - beta2_) * grad * grad;</div>
<div class="line"><a id="l00226" name="l00226"></a><span class="lineno">  226</span> </div>
<div class="line"><a id="l00227" name="l00227"></a><span class="lineno">  227</span>        <span class="keywordtype">float</span> m1_hat = m1_vec[i] / bc1;</div>
<div class="line"><a id="l00228" name="l00228"></a><span class="lineno">  228</span>        <span class="keywordtype">float</span> m2_term = m2_vec[i];</div>
<div class="line"><a id="l00229" name="l00229"></a><span class="lineno">  229</span>        <span class="keywordflow">if</span> (amsgrad_) {</div>
<div class="line"><a id="l00230" name="l00230"></a><span class="lineno">  230</span>          (*vhat_vec)[i] = std::max((*vhat_vec)[i], m2_vec[i]);</div>
<div class="line"><a id="l00231" name="l00231"></a><span class="lineno">  231</span>          m2_term = (*vhat_vec)[i];</div>
<div class="line"><a id="l00232" name="l00232"></a><span class="lineno">  232</span>        }</div>
<div class="line"><a id="l00233" name="l00233"></a><span class="lineno">  233</span>        <span class="keywordtype">float</span> m2_hat = m2_term / bc2;</div>
<div class="line"><a id="l00234" name="l00234"></a><span class="lineno">  234</span>        data[i] -= lr * m1_hat / (std::sqrt(m2_hat) + epsilon_);</div>
<div class="line"><a id="l00235" name="l00235"></a><span class="lineno">  235</span>      }</div>
<div class="line"><a id="l00236" name="l00236"></a><span class="lineno">  236</span>    }</div>
<div class="line"><a id="l00237" name="l00237"></a><span class="lineno">  237</span>  }</div>
</div>
<div class="line"><a id="l00238" name="l00238"></a><span class="lineno">  238</span> </div>
<div class="line"><a id="l00239" name="l00239"></a><span class="lineno">  239</span> <span class="keyword">private</span>:</div>
<div class="line"><a id="l00240" name="l00240"></a><span class="lineno">  240</span>  <span class="keywordtype">float</span> beta1_;</div>
<div class="line"><a id="l00241" name="l00241"></a><span class="lineno">  241</span>  <span class="keywordtype">float</span> beta2_;</div>
<div class="line"><a id="l00242" name="l00242"></a><span class="lineno">  242</span>  <span class="keywordtype">float</span> weight_decay_;</div>
<div class="line"><a id="l00243" name="l00243"></a><span class="lineno">  243</span>  [[maybe_unused]] <span class="keywordtype">bool</span> use_weight_decay_;</div>
<div class="line"><a id="l00244" name="l00244"></a><span class="lineno">  244</span>  <span class="keywordtype">bool</span> amsgrad_;</div>
<div class="line"><a id="l00245" name="l00245"></a><span class="lineno">  245</span>  <span class="keywordtype">float</span> epsilon_;</div>
<div class="line"><a id="l00246" name="l00246"></a><span class="lineno">  246</span>  std::vector&lt;std::vector&lt;float&gt;&gt; m1_;</div>
<div class="line"><a id="l00247" name="l00247"></a><span class="lineno">  247</span>  std::vector&lt;std::vector&lt;float&gt;&gt; m2_;</div>
<div class="line"><a id="l00248" name="l00248"></a><span class="lineno">  248</span>  std::vector&lt;std::vector&lt;float&gt;&gt; vhat_;</div>
<div class="line"><a id="l00249" name="l00249"></a><span class="lineno">  249</span>};</div>
</div>
<div class="line"><a id="l00250" name="l00250"></a><span class="lineno">  250</span> </div>
<div class="line"><a id="l00259" name="l00259"></a><span class="lineno">  259</span><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Scheduler&gt;</div>
<div class="foldopen" id="foldopen00260" data-start="{" data-end="};">
<div class="line"><a id="l00260" name="l00260"></a><span class="lineno"><a class="line" href="classoptim_1_1AdamW.html">  260</a></span><span class="keyword">class </span><a class="code hl_class" href="classoptim_1_1AdamW.html">AdamW</a> : <span class="keyword">public</span> <a class="code hl_class" href="classoptim_1_1OptimizerWithScheduler.html">OptimizerWithScheduler</a>&lt;Scheduler&gt; {</div>
<div class="line"><a id="l00261" name="l00261"></a><span class="lineno">  261</span> <span class="keyword">public</span>:</div>
<div class="foldopen" id="foldopen00273" data-start="{" data-end="}">
<div class="line"><a id="l00273" name="l00273"></a><span class="lineno"><a class="line" href="classoptim_1_1AdamW.html#a0314fda8f79d1780794ac03d188c99ef">  273</a></span>  <a class="code hl_function" href="classoptim_1_1AdamW.html#a0314fda8f79d1780794ac03d188c99ef">AdamW</a>(std::vector&lt;Tensor&gt; params, Scheduler&amp; scheduler, <span class="keywordtype">float</span> beta1 = 0.9f,</div>
<div class="line"><a id="l00274" name="l00274"></a><span class="lineno">  274</span>        <span class="keywordtype">float</span> beta2 = 0.999f, <span class="keywordtype">float</span> weight_decay = 0.0f,</div>
<div class="line"><a id="l00275" name="l00275"></a><span class="lineno">  275</span>        <span class="keywordtype">bool</span> use_weight_decay = <span class="keyword">false</span>, <span class="keywordtype">bool</span> amsgrad = <span class="keyword">false</span>,</div>
<div class="line"><a id="l00276" name="l00276"></a><span class="lineno">  276</span>        <span class="keywordtype">float</span> epsilon = 1e-8f)</div>
<div class="line"><a id="l00277" name="l00277"></a><span class="lineno">  277</span>      : <a class="code hl_class" href="classoptim_1_1OptimizerWithScheduler.html">OptimizerWithScheduler</a>&lt;Scheduler&gt;(std::move(params), scheduler),</div>
<div class="line"><a id="l00278" name="l00278"></a><span class="lineno">  278</span>        beta1_(beta1),</div>
<div class="line"><a id="l00279" name="l00279"></a><span class="lineno">  279</span>        beta2_(beta2),</div>
<div class="line"><a id="l00280" name="l00280"></a><span class="lineno">  280</span>        weight_decay_(weight_decay),</div>
<div class="line"><a id="l00281" name="l00281"></a><span class="lineno">  281</span>        use_weight_decay_(use_weight_decay),</div>
<div class="line"><a id="l00282" name="l00282"></a><span class="lineno">  282</span>        amsgrad_(amsgrad),</div>
<div class="line"><a id="l00283" name="l00283"></a><span class="lineno">  283</span>        epsilon_(epsilon),</div>
<div class="line"><a id="l00284" name="l00284"></a><span class="lineno">  284</span>        m1_(this-&gt;<a class="code hl_variable" href="classoptim_1_1Optimizer.html#aad43a44085c393e55f9f21012ad78e11">params_</a>.size()),</div>
<div class="line"><a id="l00285" name="l00285"></a><span class="lineno">  285</span>        m2_(this-&gt;<a class="code hl_variable" href="classoptim_1_1Optimizer.html#aad43a44085c393e55f9f21012ad78e11">params_</a>.size()),</div>
<div class="line"><a id="l00286" name="l00286"></a><span class="lineno">  286</span>        vhat_(amsgrad ? this-&gt;<a class="code hl_variable" href="classoptim_1_1Optimizer.html#aad43a44085c393e55f9f21012ad78e11">params_</a>.size() : 0) {}</div>
</div>
<div class="line"><a id="l00287" name="l00287"></a><span class="lineno">  287</span> </div>
<div class="foldopen" id="foldopen00291" data-start="{" data-end="}">
<div class="line"><a id="l00291" name="l00291"></a><span class="lineno"><a class="line" href="classoptim_1_1AdamW.html#a148915b8ec1a27d905c6c787eade49e1">  291</a></span>  <span class="keywordtype">void</span> <a class="code hl_function" href="classoptim_1_1AdamW.html#a148915b8ec1a27d905c6c787eade49e1">step</a>()<span class="keyword"> override </span>{</div>
<div class="line"><a id="l00292" name="l00292"></a><span class="lineno">  292</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> lr = this-&gt;<a class="code hl_variable" href="classoptim_1_1OptimizerWithScheduler.html#a6561fdfdb4ca2e0bcda311f6528bc33d">scheduler_</a>-&gt;get();</div>
<div class="line"><a id="l00293" name="l00293"></a><span class="lineno">  293</span>    ++this-&gt;<a class="code hl_variable" href="classoptim_1_1Optimizer.html#a76053e62b3ab69ec9fecf22d3909972e">step_count_</a>;</div>
<div class="line"><a id="l00294" name="l00294"></a><span class="lineno">  294</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> bc1 =</div>
<div class="line"><a id="l00295" name="l00295"></a><span class="lineno">  295</span>        1.0f - std::pow(beta1_, <span class="keyword">static_cast&lt;</span><span class="keywordtype">float</span><span class="keyword">&gt;</span>(this-&gt;<a class="code hl_variable" href="classoptim_1_1Optimizer.html#a76053e62b3ab69ec9fecf22d3909972e">step_count_</a>));</div>
<div class="line"><a id="l00296" name="l00296"></a><span class="lineno">  296</span>    <span class="keyword">const</span> <span class="keywordtype">float</span> bc2 =</div>
<div class="line"><a id="l00297" name="l00297"></a><span class="lineno">  297</span>        1.0f - std::pow(beta2_, <span class="keyword">static_cast&lt;</span><span class="keywordtype">float</span><span class="keyword">&gt;</span>(this-&gt;<a class="code hl_variable" href="classoptim_1_1Optimizer.html#a76053e62b3ab69ec9fecf22d3909972e">step_count_</a>));</div>
<div class="line"><a id="l00298" name="l00298"></a><span class="lineno">  298</span> </div>
<div class="line"><a id="l00299" name="l00299"></a><span class="lineno">  299</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> idx = 0; idx &lt; this-&gt;<a class="code hl_variable" href="classoptim_1_1Optimizer.html#aad43a44085c393e55f9f21012ad78e11">params_</a>.size(); ++idx) {</div>
<div class="line"><a id="l00300" name="l00300"></a><span class="lineno">  300</span>      <a class="code hl_struct" href="structTensor.html">Tensor</a>&amp; param = this-&gt;<a class="code hl_variable" href="classoptim_1_1Optimizer.html#aad43a44085c393e55f9f21012ad78e11">params_</a>[idx];</div>
<div class="line"><a id="l00301" name="l00301"></a><span class="lineno">  301</span>      <span class="keywordflow">if</span> (!<a class="code hl_function" href="classoptim_1_1Optimizer.html#ae49f7491e2f65b815afcfd94d5f1671b">Optimizer::valid_param</a>(param)) <span class="keywordflow">continue</span>;</div>
<div class="line"><a id="l00302" name="l00302"></a><span class="lineno">  302</span>      <span class="keywordtype">float</span>* data = param.<a class="code hl_function" href="structTensor.html#a68b3bf158149399d366aee5cf21aa951">data</a>();</div>
<div class="line"><a id="l00303" name="l00303"></a><span class="lineno">  303</span>      <span class="keyword">const</span> <span class="keywordtype">float</span>* grad_ptr = param.<a class="code hl_function" href="structTensor.html#afaed2ad287228df5d00eb689ad8d3776">grad</a>();</div>
<div class="line"><a id="l00304" name="l00304"></a><span class="lineno">  304</span>      <span class="keyword">const</span> <span class="keywordtype">size_t</span> n = param.<a class="code hl_variable" href="structTensor.html#a10ca340abccb2fa3476d3ec64346c238">numel</a>;</div>
<div class="line"><a id="l00305" name="l00305"></a><span class="lineno">  305</span>      <a class="code hl_function" href="classoptim_1_1Optimizer.html#ae7308bc1b1f376b6a9cb7ae66c3af88e">Optimizer::ensure_state_size</a>(m1_[idx], n);</div>
<div class="line"><a id="l00306" name="l00306"></a><span class="lineno">  306</span>      <a class="code hl_function" href="classoptim_1_1Optimizer.html#ae7308bc1b1f376b6a9cb7ae66c3af88e">Optimizer::ensure_state_size</a>(m2_[idx], n);</div>
<div class="line"><a id="l00307" name="l00307"></a><span class="lineno">  307</span>      <span class="keywordflow">if</span> (amsgrad_) {</div>
<div class="line"><a id="l00308" name="l00308"></a><span class="lineno">  308</span>        <a class="code hl_function" href="classoptim_1_1Optimizer.html#ae7308bc1b1f376b6a9cb7ae66c3af88e">Optimizer::ensure_state_size</a>(vhat_[idx], n);</div>
<div class="line"><a id="l00309" name="l00309"></a><span class="lineno">  309</span>      }</div>
<div class="line"><a id="l00310" name="l00310"></a><span class="lineno">  310</span>      <span class="keyword">auto</span>&amp; m1_vec = m1_[idx];</div>
<div class="line"><a id="l00311" name="l00311"></a><span class="lineno">  311</span>      <span class="keyword">auto</span>&amp; m2_vec = m2_[idx];</div>
<div class="line"><a id="l00312" name="l00312"></a><span class="lineno">  312</span>      std::vector&lt;float&gt;* vhat_vec = amsgrad_ ? &amp;vhat_[idx] : <span class="keyword">nullptr</span>;</div>
<div class="line"><a id="l00313" name="l00313"></a><span class="lineno">  313</span> </div>
<div class="line"><a id="l00314" name="l00314"></a><span class="lineno">  314</span>      <span class="keywordflow">if</span> (use_weight_decay_ &amp;&amp; weight_decay_ != 0.0f) {</div>
<div class="line"><a id="l00315" name="l00315"></a><span class="lineno">  315</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; n; ++i) {</div>
<div class="line"><a id="l00316" name="l00316"></a><span class="lineno">  316</span>          data[i] -= lr * weight_decay_ * data[i];</div>
<div class="line"><a id="l00317" name="l00317"></a><span class="lineno">  317</span>        }</div>
<div class="line"><a id="l00318" name="l00318"></a><span class="lineno">  318</span>      }</div>
<div class="line"><a id="l00319" name="l00319"></a><span class="lineno">  319</span> </div>
<div class="line"><a id="l00320" name="l00320"></a><span class="lineno">  320</span>      <span class="keywordflow">if</span> (amsgrad_) {</div>
<div class="line"><a id="l00321" name="l00321"></a><span class="lineno">  321</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; n; ++i) {</div>
<div class="line"><a id="l00322" name="l00322"></a><span class="lineno">  322</span>          <span class="keywordtype">float</span> grad = grad_ptr[i];</div>
<div class="line"><a id="l00323" name="l00323"></a><span class="lineno">  323</span>          m1_vec[i] = beta1_ * m1_vec[i] + (1.0f - beta1_) * grad;</div>
<div class="line"><a id="l00324" name="l00324"></a><span class="lineno">  324</span>          m2_vec[i] = beta2_ * m2_vec[i] + (1.0f - beta2_) * grad * grad;</div>
<div class="line"><a id="l00325" name="l00325"></a><span class="lineno">  325</span> </div>
<div class="line"><a id="l00326" name="l00326"></a><span class="lineno">  326</span>          <span class="comment">// 55%</span></div>
<div class="line"><a id="l00327" name="l00327"></a><span class="lineno">  327</span>          <span class="keywordtype">float</span> m1_hat = m1_vec[i] / bc1;</div>
<div class="line"><a id="l00328" name="l00328"></a><span class="lineno">  328</span>          <span class="keywordtype">float</span> m2_term = m2_vec[i];</div>
<div class="line"><a id="l00329" name="l00329"></a><span class="lineno">  329</span>          (*vhat_vec)[i] = std::max((*vhat_vec)[i], m2_vec[i]);</div>
<div class="line"><a id="l00330" name="l00330"></a><span class="lineno">  330</span>          m2_term = (*vhat_vec)[i];</div>
<div class="line"><a id="l00331" name="l00331"></a><span class="lineno">  331</span>          <span class="keywordtype">float</span> m2_hat = m2_term / bc2;</div>
<div class="line"><a id="l00332" name="l00332"></a><span class="lineno">  332</span>          <span class="comment">// 30%</span></div>
<div class="line"><a id="l00333" name="l00333"></a><span class="lineno">  333</span>          data[i] -= lr * m1_hat / (std::sqrt(m2_hat) + epsilon_);</div>
<div class="line"><a id="l00334" name="l00334"></a><span class="lineno">  334</span>        }</div>
<div class="line"><a id="l00335" name="l00335"></a><span class="lineno">  335</span> </div>
<div class="line"><a id="l00336" name="l00336"></a><span class="lineno">  336</span>      } <span class="keywordflow">else</span> {</div>
<div class="line"><a id="l00337" name="l00337"></a><span class="lineno">  337</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; n; ++i) {</div>
<div class="line"><a id="l00338" name="l00338"></a><span class="lineno">  338</span>          <span class="keywordtype">float</span> grad = grad_ptr[i];</div>
<div class="line"><a id="l00339" name="l00339"></a><span class="lineno">  339</span>          m1_vec[i] = beta1_ * m1_vec[i] + (1.0f - beta1_) * grad;</div>
<div class="line"><a id="l00340" name="l00340"></a><span class="lineno">  340</span>          m2_vec[i] = beta2_ * m2_vec[i] + (1.0f - beta2_) * grad * grad;</div>
<div class="line"><a id="l00341" name="l00341"></a><span class="lineno">  341</span> </div>
<div class="line"><a id="l00342" name="l00342"></a><span class="lineno">  342</span>          <span class="comment">// 55%</span></div>
<div class="line"><a id="l00343" name="l00343"></a><span class="lineno">  343</span>          <span class="keywordtype">float</span> m1_hat = m1_vec[i] / bc1;</div>
<div class="line"><a id="l00344" name="l00344"></a><span class="lineno">  344</span>          <span class="keywordtype">float</span> m2_term = m2_vec[i];</div>
<div class="line"><a id="l00345" name="l00345"></a><span class="lineno">  345</span>          <span class="keywordtype">float</span> m2_hat = m2_term / bc2;</div>
<div class="line"><a id="l00346" name="l00346"></a><span class="lineno">  346</span>          <span class="comment">// 30%</span></div>
<div class="line"><a id="l00347" name="l00347"></a><span class="lineno">  347</span>          data[i] -= lr * m1_hat / (std::sqrt(m2_hat) + epsilon_);</div>
<div class="line"><a id="l00348" name="l00348"></a><span class="lineno">  348</span>        }</div>
<div class="line"><a id="l00349" name="l00349"></a><span class="lineno">  349</span>      }</div>
<div class="line"><a id="l00350" name="l00350"></a><span class="lineno">  350</span>    }</div>
<div class="line"><a id="l00351" name="l00351"></a><span class="lineno">  351</span>  }</div>
</div>
<div class="line"><a id="l00352" name="l00352"></a><span class="lineno">  352</span> </div>
<div class="line"><a id="l00353" name="l00353"></a><span class="lineno">  353</span> <span class="keyword">private</span>:</div>
<div class="line"><a id="l00354" name="l00354"></a><span class="lineno">  354</span>  <span class="keywordtype">float</span> beta1_;</div>
<div class="line"><a id="l00355" name="l00355"></a><span class="lineno">  355</span>  <span class="keywordtype">float</span> beta2_;</div>
<div class="line"><a id="l00356" name="l00356"></a><span class="lineno">  356</span>  <span class="keywordtype">float</span> weight_decay_;</div>
<div class="line"><a id="l00357" name="l00357"></a><span class="lineno">  357</span>  <span class="keywordtype">bool</span> use_weight_decay_;</div>
<div class="line"><a id="l00358" name="l00358"></a><span class="lineno">  358</span>  <span class="keywordtype">bool</span> amsgrad_;</div>
<div class="line"><a id="l00359" name="l00359"></a><span class="lineno">  359</span>  <span class="keywordtype">float</span> epsilon_;</div>
<div class="line"><a id="l00360" name="l00360"></a><span class="lineno">  360</span>  std::vector&lt;std::vector&lt;float&gt;&gt; m1_;</div>
<div class="line"><a id="l00361" name="l00361"></a><span class="lineno">  361</span>  std::vector&lt;std::vector&lt;float&gt;&gt; m2_;</div>
<div class="line"><a id="l00362" name="l00362"></a><span class="lineno">  362</span>  std::vector&lt;std::vector&lt;float&gt;&gt; vhat_;</div>
<div class="line"><a id="l00363" name="l00363"></a><span class="lineno">  363</span>};</div>
</div>
<div class="line"><a id="l00364" name="l00364"></a><span class="lineno">  364</span> </div>
<div class="line"><a id="l00365" name="l00365"></a><span class="lineno">  365</span>}  <span class="comment">// namespace optim</span></div>
</div>
<div class="ttc" id="aclassoptim_1_1AdamW_html"><div class="ttname"><a href="classoptim_1_1AdamW.html">optim::AdamW</a></div><div class="ttdoc">AdamW optimizer with decoupled weight decay.</div><div class="ttdef"><b>Definition</b> optimizer.hpp:260</div></div>
<div class="ttc" id="aclassoptim_1_1AdamW_html_a0314fda8f79d1780794ac03d188c99ef"><div class="ttname"><a href="classoptim_1_1AdamW.html#a0314fda8f79d1780794ac03d188c99ef">optim::AdamW::AdamW</a></div><div class="ttdeci">AdamW(std::vector&lt; Tensor &gt; params, Scheduler &amp;scheduler, float beta1=0.9f, float beta2=0.999f, float weight_decay=0.0f, bool use_weight_decay=false, bool amsgrad=false, float epsilon=1e-8f)</div><div class="ttdoc">Construct AdamW optimizer.</div><div class="ttdef"><b>Definition</b> optimizer.hpp:273</div></div>
<div class="ttc" id="aclassoptim_1_1AdamW_html_a148915b8ec1a27d905c6c787eade49e1"><div class="ttname"><a href="classoptim_1_1AdamW.html#a148915b8ec1a27d905c6c787eade49e1">optim::AdamW::step</a></div><div class="ttdeci">void step() override</div><div class="ttdoc">Perform AdamW update step.</div><div class="ttdef"><b>Definition</b> optimizer.hpp:291</div></div>
<div class="ttc" id="aclassoptim_1_1Adam_html"><div class="ttname"><a href="classoptim_1_1Adam.html">optim::Adam</a></div><div class="ttdoc">Adam optimizer with weight decay.</div><div class="ttdef"><b>Definition</b> optimizer.hpp:164</div></div>
<div class="ttc" id="aclassoptim_1_1Adam_html_ab9bc3c3903f4bc32af2e16d99b5ce566"><div class="ttname"><a href="classoptim_1_1Adam.html#ab9bc3c3903f4bc32af2e16d99b5ce566">optim::Adam::Adam</a></div><div class="ttdeci">Adam(std::vector&lt; Tensor &gt; params, Scheduler &amp;scheduler, float beta1=0.9f, float beta2=0.999f, float weight_decay=0.0f, bool use_weight_decay=false, bool amsgrad=false, float epsilon=1e-8f)</div><div class="ttdoc">Construct Adam optimizer.</div><div class="ttdef"><b>Definition</b> optimizer.hpp:177</div></div>
<div class="ttc" id="aclassoptim_1_1Adam_html_ac94daadd6de7e3c908824638aa72736a"><div class="ttname"><a href="classoptim_1_1Adam.html#ac94daadd6de7e3c908824638aa72736a">optim::Adam::step</a></div><div class="ttdeci">void step() override</div><div class="ttdoc">Perform Adam update step.</div><div class="ttdef"><b>Definition</b> optimizer.hpp:195</div></div>
<div class="ttc" id="aclassoptim_1_1OptimizerWithScheduler_html"><div class="ttname"><a href="classoptim_1_1OptimizerWithScheduler.html">optim::OptimizerWithScheduler</a></div><div class="ttdoc">Base class for optimizers that use learning rate schedulers.</div><div class="ttdef"><b>Definition</b> optimizer.hpp:86</div></div>
<div class="ttc" id="aclassoptim_1_1OptimizerWithScheduler_html_a6561fdfdb4ca2e0bcda311f6528bc33d"><div class="ttname"><a href="classoptim_1_1OptimizerWithScheduler.html#a6561fdfdb4ca2e0bcda311f6528bc33d">optim::OptimizerWithScheduler::scheduler_</a></div><div class="ttdeci">Scheduler * scheduler_</div><div class="ttdoc">Pointer to learning rate scheduler.</div><div class="ttdef"><b>Definition</b> optimizer.hpp:88</div></div>
<div class="ttc" id="aclassoptim_1_1OptimizerWithScheduler_html_afeb623ea67dc878f3cbaa6d622aa1b9b"><div class="ttname"><a href="classoptim_1_1OptimizerWithScheduler.html#afeb623ea67dc878f3cbaa6d622aa1b9b">optim::OptimizerWithScheduler::OptimizerWithScheduler</a></div><div class="ttdeci">OptimizerWithScheduler(std::vector&lt; Tensor &gt; params, Scheduler &amp;scheduler)</div><div class="ttdoc">Construct optimizer with scheduler.</div><div class="ttdef"><b>Definition</b> optimizer.hpp:96</div></div>
<div class="ttc" id="aclassoptim_1_1Optimizer_html"><div class="ttname"><a href="classoptim_1_1Optimizer.html">optim::Optimizer</a></div><div class="ttdoc">Base class for optimization algorithms.</div><div class="ttdef"><b>Definition</b> optimizer.hpp:30</div></div>
<div class="ttc" id="aclassoptim_1_1Optimizer_html_a37b4a35ba858e7f42b59b0fa70a161fe"><div class="ttname"><a href="classoptim_1_1Optimizer.html#a37b4a35ba858e7f42b59b0fa70a161fe">optim::Optimizer::zero_grad</a></div><div class="ttdeci">void zero_grad()</div><div class="ttdoc">Zero gradients for all parameters.</div><div class="ttdef"><b>Definition</b> optimizer.hpp:47</div></div>
<div class="ttc" id="aclassoptim_1_1Optimizer_html_a76053e62b3ab69ec9fecf22d3909972e"><div class="ttname"><a href="classoptim_1_1Optimizer.html#a76053e62b3ab69ec9fecf22d3909972e">optim::Optimizer::step_count_</a></div><div class="ttdeci">size_t step_count_</div><div class="ttdoc">Number of steps taken.</div><div class="ttdef"><b>Definition</b> optimizer.hpp:33</div></div>
<div class="ttc" id="aclassoptim_1_1Optimizer_html_a7dfe439ca1d1fd030c87b01566c33757"><div class="ttname"><a href="classoptim_1_1Optimizer.html#a7dfe439ca1d1fd030c87b01566c33757">optim::Optimizer::Optimizer</a></div><div class="ttdeci">Optimizer(std::vector&lt; Tensor &gt; params)</div><div class="ttdoc">Construct optimizer with parameters.</div><div class="ttdef"><b>Definition</b> optimizer.hpp:40</div></div>
<div class="ttc" id="aclassoptim_1_1Optimizer_html_a8844cd33a9d0ac230ebc6f47b03efd27"><div class="ttname"><a href="classoptim_1_1Optimizer.html#a8844cd33a9d0ac230ebc6f47b03efd27">optim::Optimizer::~Optimizer</a></div><div class="ttdeci">virtual ~Optimizer()=default</div></div>
<div class="ttc" id="aclassoptim_1_1Optimizer_html_aad43a44085c393e55f9f21012ad78e11"><div class="ttname"><a href="classoptim_1_1Optimizer.html#aad43a44085c393e55f9f21012ad78e11">optim::Optimizer::params_</a></div><div class="ttdeci">std::vector&lt; Tensor &gt; params_</div><div class="ttdoc">Learnable parameters to optimize.</div><div class="ttdef"><b>Definition</b> optimizer.hpp:32</div></div>
<div class="ttc" id="aclassoptim_1_1Optimizer_html_ad9a5904b78707346eeab961629342af7"><div class="ttname"><a href="classoptim_1_1Optimizer.html#ad9a5904b78707346eeab961629342af7">optim::Optimizer::step</a></div><div class="ttdeci">virtual void step()=0</div><div class="ttdoc">Perform one optimization step.</div></div>
<div class="ttc" id="aclassoptim_1_1Optimizer_html_ae49f7491e2f65b815afcfd94d5f1671b"><div class="ttname"><a href="classoptim_1_1Optimizer.html#ae49f7491e2f65b815afcfd94d5f1671b">optim::Optimizer::valid_param</a></div><div class="ttdeci">static bool valid_param(const Tensor &amp;t)</div><div class="ttdoc">Check if parameter tensor is valid for optimization.</div><div class="ttdef"><b>Definition</b> optimizer.hpp:75</div></div>
<div class="ttc" id="aclassoptim_1_1Optimizer_html_ae7308bc1b1f376b6a9cb7ae66c3af88e"><div class="ttname"><a href="classoptim_1_1Optimizer.html#ae7308bc1b1f376b6a9cb7ae66c3af88e">optim::Optimizer::ensure_state_size</a></div><div class="ttdeci">static void ensure_state_size(std::vector&lt; float &gt; &amp;state, size_t target)</div><div class="ttdoc">Ensure optimizer state vector has correct size.</div><div class="ttdef"><b>Definition</b> optimizer.hpp:64</div></div>
<div class="ttc" id="aclassoptim_1_1SGD_html"><div class="ttname"><a href="classoptim_1_1SGD.html">optim::SGD</a></div><div class="ttdoc">Stochastic Gradient Descent optimizer with momentum.</div><div class="ttdef"><b>Definition</b> optimizer.hpp:108</div></div>
<div class="ttc" id="aclassoptim_1_1SGD_html_a7a4eec9b6d27035ec02ffb51422e88ff"><div class="ttname"><a href="classoptim_1_1SGD.html#a7a4eec9b6d27035ec02ffb51422e88ff">optim::SGD::SGD</a></div><div class="ttdeci">SGD(std::vector&lt; Tensor &gt; params, Scheduler &amp;scheduler, float momentum_beta=0.0f)</div><div class="ttdoc">Construct SGD optimizer.</div><div class="ttdef"><b>Definition</b> optimizer.hpp:116</div></div>
<div class="ttc" id="aclassoptim_1_1SGD_html_af563ec82e2b7929afbd28dbf549b50af"><div class="ttname"><a href="classoptim_1_1SGD.html#af563ec82e2b7929afbd28dbf549b50af">optim::SGD::step</a></div><div class="ttdeci">void step() override</div><div class="ttdoc">Perform SGD update step.</div><div class="ttdef"><b>Definition</b> optimizer.hpp:125</div></div>
<div class="ttc" id="anamespaceoptim_html"><div class="ttname"><a href="namespaceoptim.html">optim</a></div><div class="ttdef"><b>Definition</b> optimizer.hpp:21</div></div>
<div class="ttc" id="astructTensor_html"><div class="ttname"><a href="structTensor.html">Tensor</a></div><div class="ttdoc">Lightweight tensor view with automatic differentiation support.</div><div class="ttdef"><b>Definition</b> tensor.hpp:79</div></div>
<div class="ttc" id="astructTensor_html_a10ca340abccb2fa3476d3ec64346c238"><div class="ttname"><a href="structTensor.html#a10ca340abccb2fa3476d3ec64346c238">Tensor::numel</a></div><div class="ttdeci">size_t numel</div><div class="ttdoc">Total number of elements (product of shape)</div><div class="ttdef"><b>Definition</b> tensor.hpp:83</div></div>
<div class="ttc" id="astructTensor_html_a68b3bf158149399d366aee5cf21aa951"><div class="ttname"><a href="structTensor.html#a68b3bf158149399d366aee5cf21aa951">Tensor::data</a></div><div class="ttdeci">float * data()</div><div class="ttdoc">Get mutable pointer to tensor data.</div></div>
<div class="ttc" id="astructTensor_html_afaed2ad287228df5d00eb689ad8d3776"><div class="ttname"><a href="structTensor.html#afaed2ad287228df5d00eb689ad8d3776">Tensor::grad</a></div><div class="ttdeci">float * grad()</div><div class="ttdoc">Get mutable pointer to gradient buffer.</div></div>
<div class="ttc" id="atensor_8hpp_html"><div class="ttname"><a href="tensor_8hpp.html">tensor.hpp</a></div><div class="ttdoc">Core tensor library providing automatic differentiation and memory management.</div></div>
<div class="ttc" id="autils_8hpp_html"><div class="ttname"><a href="utils_8hpp.html">utils.hpp</a></div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a class="el" href="optimizer_8hpp.html">optimizer.hpp</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>
